# Langchain-Chatbot

## Overview
This project contains chatbot built using Langchain library and tested via connecting to Mistral-7B model running locally at LM studio. Future modifications described below are planned for this project in order to gain practival NLP and AI knowledge.

## Already Implemented
- Chatbot working in two modes: first in conversational manner with memory and second in retrieval manner without memory in order to test RAG performance

## Planned
- Improve RAG with FLARE

## Usage
To interact with chatbot locally, follow these steps:
1. In LM studio load model like Mistral 7B and start local server.
2. Run `app.py` file to initialize chatbot and interact with it.

## Example Usage
Conversational mode - conversation_example.png

## Author
Aliaksandr Marchuk